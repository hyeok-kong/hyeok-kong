##### 핵심 단어!
- 토픽, 파티션, 레코드
- 오프셋
- 영속성
- 레플리케이션
- 리밸런스
- 로그 세그먼트


##### 카프카의 영속성
- 카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를 메모리에 저장하지 않고 **파일 시스템**에 저장함
- 파일 시스템의 비교적 느린 속도를 해결하기 위해 운영체제 레벨에서 파일 시스템을 최대한 활용
	- 파일 I/O 성능 향상을 위해 **페이지 캐시 영역**을 메모리에 따로 생성하여 사용
	- 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하기에 빠른것
	- 파일 시스템
	- 또한, 파일 기반이기에 프로세스가 급작스럽게 종료되더라도 데이터가 보존됨

##### 순서 보장?
카프카는 기본적으로 파티션에 대해서 순서를 보장함
데이터 순서를 보장하고 싶다면 1개의 파티션으로 이루어진 토픽을 만들어야 함

##### 데이터 복제, 싱크
데이터 복제(replication)는 카프카를 장애 허용 시스템(fault tolerant system)으로 동작하도록 하는 원동력
카프카의 데이터 복제는 파티션 단위로 이루어짐 --> 엘라스틱서치에서 샤드 단위로 복제되는 느낌

##### 컨트롤러
클러스터의 브로커들 중 한대가 컨트롤러의 역할을 함

동작
- 다른 브로커들의 상태를 체크
- 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배

##### 데이터 삭제
데이터 삭제는 오직 브로커만이 할 수 있음 (프로듀서, 컨슈머는 요청할 수도 없음)
삭제는 파일 단위로 이루어짐 --> 이 단위를 **로그 세그먼트** 라고 부름
- 다수의 데이터가 들어 있기 때문에 DB처럼 골라서 삭제할 수 없음
- 데이터가 쌓이는 동안엔 파일 시스템으로 열려있음
- 파일이 닫히는 기본 값은 1GB. 설정할 수 있지만, 너무 작게 하면 파일을 자주 여닫아 성능 하락

##### 컨슈머 오프셋 저장
컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고, 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋
- 커밋한 오프셋은 \_\_consumer_offsets 토픽에 저장됨, 이걸 토대로 컨슈머 그룹이 다음 레코드를 찾음

##### 코디네이터(coordinator)
클러스터의 브로커들 중 한 대는 코디네이터의 역할을 수행
- 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배
	- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 재할당
	- 이 과정을 **리밸런스(rebalance)** 라고 함

##### 주키퍼가 필요한 이유?
주키퍼는 카프카의 메타데이터를 관리하는 데에 사용됨
- 카프카 클러스터로 묶인 브로커들은 동일한 주키퍼 경로를 선언해야 같은 묶음으로 동작

##### 토픽과 파티션
토픽 : 카프카에서 데이터를 구분하기 위해 사용하는 단위 (DB의 table)
- 1개 이상의 파티션을 소유함
- 파티션엔 프로듀서가 보낸 데이터들이 저장됨 --> 이걸 **레코드**라고 함

파티션은 카프카의 병렬처리의 핵심
- 컨슈머 그룹이 레코드를 병렬로 처리함
- 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬 처리하는 가장 좋은 방법은 컨슈머 개수를 늘려 스케일아웃 + 파티션 개수 늘리기

파티션은 queue와 비슷한 구조임
- But 사용한 데이터가 삭제되지 않음 --> 동일한 데이터를 여러 번 가져갈 수 있음

토픽 이름 변경을 지원하지 않음
- 처음부터 규칙을 정하고 잘 작성하자

##### 레코드
- 구성 : 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더
브로커에 한번 적재된 레코드는 수정할 수 없음, 기간 혹은 용량에 따라서만 삭제됨

타임스탬프는 레코드 생성 시점의 유닉스 타임으로 설정됨. 하지만
- 프로듀서가 레코드 생성할 때 임의의 값 설정 가능
- 토픽 설정에 따라 브로커에 적재된 시간으로 설정될 수도 있음

키를 지정해서 메세지를 보내면 해시를 통해 파티션을 지정함
- 즉, 같은 키는 모두 하나의 파티션으로 들어갈 수 있음
- 다만, 파티션을 지정할 수는 없음
- 또한, 파티션 개수가 변경되면 기존과 파티션 매칭이 달라짐
- 키 지정 안하면 배치를 통해 RR 방식으로  들어감

#### 카프카 클라이언트
##### 프로듀서
프로듀서 생성 시 파티셔너를 따로 지정하지 않으면 DefaultPartitioner로 설정됨
- UniformStickyPartitioner : 배치 단위로 묶어서 한번에 보냄 --> 성능 향상

Partitioner 인터페이스를 구현해 사용자 지정 파티셔너를 만들 수 있음
압축 옵션 지정 가능 : 네트워크 처리량에서 이득, cpu 등 리소스 사용량에서 손해

###### 필수 옵션
- bootstrap.servers : 데이터를 전송할 대상 카프카 클러스터에 속한 브로커 정보를 작성
- key.serializer : 레코드의 메시지 키를 직렬화하는 클래스 지정
- value.serializer : 레코드의 메시지 값을 직렬화하는 클래스를 지정

##### 컨슈머
두가지 운영 방법
###### 1. 1개 이상의 컨슈머로 이루어진 컨슈머 그룹을 운영
- 컨슈머 그룹의 컨슈머 개수는 토픽의 파티션 개수보다 같거나 작아야 함
	- 1개의 파티션은 최대 1개의 컨슈머에 할당 가능
	- 1개의 컨슈머는 여러 개의 파티션에 할당 가능

- 컨슈머 그룹은 다른 컨슈머 그룹과 격리됨
	- 각자 다른 로직이라면 분리해서 하자. 장애 대응에 도움이 된다.

- 컨슈머에 장애가 발생한다면?
	- **리밸런싱** --> 파티션의 소유권이 다른 컨슈머에게 넘어감
		- 컨슈머가 추가되는 상황, 컨슈머가 제외되는 상황에 발생
		- 리밸런싱 과정에서 해당 컨슈머 그룹의 컨슈머는 토픽의 데이터를 읽을 수 없음
		- **group coordinator** 는 리밸런싱을 발동시키는 역할을 함, 브로커 중 한 대가 담당

- 컨슈머가 오프셋 커밋을 정상적으로 처리했는지 검증해야 함
	- 안하면 오프셋이 커밋되지 않았을 경우 중복 데이터 처리 문제 발생

- 자동 커밋?
	- poll() 메서드 수행될 때 일정 간격마다 오프셋을 커밋하도록 함
	- enable.auto.commit=true
	- 코드상에서 따로 커밋 관련 코드를 작성할 필요가 없음
	- 컨슈머에 이슈 발생 시 데이터 유실 혹은 중복 발생 가능

- commitSync()
	- poll() 메서드에 반환된 마지막 오프셋을 기준으로 커밋 수행
	- 동기적으로 동작하기에 처리량에 영향이 감

- commitAsync()
	- 비동기적으로 작동
	- 순서 보장 불가, 중복 데이터 처리 문제 발생 가능

- Fetcher?
	- 컨슈머 애플리케이션 실행 시 내부에서 Fetcher 인스턴스가 생성
	- poll() 메소드 호출 전 미리 레코드들을 내부 큐로 가져옴
	- 이후 poll() 메소드 호출 시 내부 큐에 있는 레코드를 반환받아 처리 수행

- 리밸런스 리스너?
	- poll() 메서드를 통해 받은 데이터를 커밋하기 전 리밸런스 발생 시 데이터 중복 처리 발생
	- 리밸런스 발생 감지를 위한 `ConsumerRebalanceListener` 인터페이스 지원
		- `onPartitionAssigned()` : 리밸런스가 끝난 뒤에 파티션 할당 완료시 호출
		- `onPartitionRevoked()` : 리밸런스가 시작되기 직전에 호출

###### 2. 토픽의 특정 파티션만 구독하는 컨슈머를 운영
- assign() 메서드를 통해 특정 파티션에 대한 컨슈머를 다룰 수 있음

###### 컨슈머의 안전한 종료
- 정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할때까지 컨슈머 그룹에 남게 됨
- `KafkaConsumer` 클래스의 wakeup() 메서드를 실행하여 인스턴스를 안전하게 종료 가능
	- wakeup() 발생 후 poll() 실행 시 `WakeupException` 발생, 이후 close 하면 안전하게 종료 가능
- `wakeup()` 은 어디서 호출하면 될까?
	- java의 경우 shutdown hook을 구현하면 kill -TERM {PID} 로 셧다운 훅을 발생시킬 수 있음

##### 어드민 API
- `AdminClient` 클래스를 통해 클러스터 옵션 같은 부분을 자동화 할 수 있음
